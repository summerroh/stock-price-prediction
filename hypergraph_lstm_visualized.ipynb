{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 00:00:39.239376: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-07 00:00:39.526628: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738886439.634191      15 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738886439.663455      15 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-07 00:00:39.944901: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[*********************100%***********************]  6 of 6 completed\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Adj Close'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Adj Close'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 155\u001b[0m\n\u001b[1;32m    152\u001b[0m     test_model_with_hypergraph(model, stock_data, H)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 137\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    134\u001b[0m end_date \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023-01-01\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Fetch stock data\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m stock_data \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_stock_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtickers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# Create and visualize hypergraph structure\u001b[39;00m\n\u001b[1;32m    140\u001b[0m num_clusters \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m, in \u001b[0;36mfetch_stock_data\u001b[0;34m(tickers, start_date, end_date)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch_stock_data\u001b[39m(tickers, start_date, end_date):\n\u001b[0;32m---> 11\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43myf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtickers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_date\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAdj Close\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     12\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mfillna(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mffill\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py:4101\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_single_key:\n\u001b[1;32m   4100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 4101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_multilevel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4102\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py:4159\u001b[0m, in \u001b[0;36mDataFrame._getitem_multilevel\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_getitem_multilevel\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m   4158\u001b[0m     \u001b[38;5;66;03m# self.columns is a MultiIndex\u001b[39;00m\n\u001b[0;32m-> 4159\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, (\u001b[38;5;28mslice\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray)):\n\u001b[1;32m   4161\u001b[0m         new_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns[loc]\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/multi.py:3040\u001b[0m, in \u001b[0;36mMultiIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mask\n\u001b[1;32m   3039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m-> 3040\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_level_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3041\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _maybe_to_slice(loc)\n\u001b[1;32m   3043\u001b[0m keylen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(key)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/multi.py:3391\u001b[0m, in \u001b[0;36mMultiIndex._get_level_indexer\u001b[0;34m(self, key, level, indexer)\u001b[0m\n\u001b[1;32m   3388\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mslice\u001b[39m(i, j, step)\n\u001b[1;32m   3390\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3391\u001b[0m     idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_loc_single_level_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlevel_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lexsort_depth \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   3394\u001b[0m         \u001b[38;5;66;03m# Desired level is not sorted\u001b[39;00m\n\u001b[1;32m   3395\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mslice\u001b[39m):\n\u001b[1;32m   3396\u001b[0m             \u001b[38;5;66;03m# test_get_loc_partial_timestamp_multiindex\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/multi.py:2980\u001b[0m, in \u001b[0;36mMultiIndex._get_loc_single_level_index\u001b[0;34m(self, level_index, key)\u001b[0m\n\u001b[1;32m   2978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2979\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2980\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlevel_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Adj Close'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import yfinance as yf\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Function to fetch stock data from yfinance\n",
    "def fetch_stock_data(tickers, start_date, end_date):\n",
    "    data = yf.download(tickers, start=start_date, end=end_date)['Adj Close']\n",
    "    data = data.fillna(method='ffill')\n",
    "    return data\n",
    "\n",
    "# Function to visualize correlation matrix and clusters\n",
    "def visualize_correlations_and_clusters(stock_data, labels):\n",
    "    # Calculate correlation matrix\n",
    "    returns = stock_data.pct_change().dropna()\n",
    "    correlation_matrix = returns.corr()\n",
    "    \n",
    "    # Plot correlation heatmap\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "    plt.title('Stock Correlation Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "    # Visualize clusters\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, ticker in enumerate(stock_data.columns):\n",
    "        plt.scatter(i, 0, c=f'C{labels[i]}', s=100, label=f'{ticker} (Cluster {labels[i]})')\n",
    "    plt.title('Stock Clusters')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "\n",
    "# Function to create hyperedges from correlation (with visualization)\n",
    "def create_hyperedges_from_correlation(stock_data, num_clusters):\n",
    "    returns = stock_data.pct_change().dropna()\n",
    "    correlation_matrix = returns.corr()\n",
    "    distance_matrix = 1 - correlation_matrix\n",
    "    \n",
    "    clustering = AgglomerativeClustering(n_clusters=num_clusters, \n",
    "                                       affinity='precomputed', \n",
    "                                       linkage='average')\n",
    "    labels = clustering.fit_predict(distance_matrix)\n",
    "    \n",
    "    # Create incidence matrix\n",
    "    num_tickers = len(stock_data.columns)\n",
    "    H = np.zeros((num_tickers, num_clusters))\n",
    "    for ticker_idx, cluster_label in enumerate(labels):\n",
    "        H[ticker_idx, cluster_label] = 1\n",
    "    \n",
    "    # Visualize correlations and clusters\n",
    "    visualize_correlations_and_clusters(stock_data, labels)\n",
    "    \n",
    "    return H, correlation_matrix\n",
    "\n",
    "# Custom LSTM-Hypergraph Model (with model structure visualization)\n",
    "class LSTMHypergraphModel(tf.keras.Model):\n",
    "    def __init__(self, lstm_units, num_tickers, num_clusters):\n",
    "        super(LSTMHypergraphModel, self).__init__()\n",
    "        self.lstm = tf.keras.layers.LSTM(lstm_units, return_sequences=False)\n",
    "        self.dense = tf.keras.layers.Dense(num_tickers)\n",
    "        \n",
    "        # Store architecture for visualization\n",
    "        self.architecture = {\n",
    "            'lstm_units': lstm_units,\n",
    "            'num_tickers': num_tickers,\n",
    "            'num_clusters': num_clusters\n",
    "        }\n",
    "    \n",
    "    def call(self, inputs, incidence_matrix):\n",
    "        lstm_output = self.lstm(inputs)\n",
    "        stock_features = self.dense(lstm_output)\n",
    "        hypergraph_output = tf.matmul(stock_features, incidence_matrix)\n",
    "        final_output = tf.matmul(hypergraph_output, tf.transpose(incidence_matrix))\n",
    "        return final_output\n",
    "    \n",
    "    def visualize_architecture(self):\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        \n",
    "        # Define components\n",
    "        components = ['Input', 'LSTM', 'Dense', 'Hypergraph', 'Output']\n",
    "        y_positions = np.linspace(0, 1, len(components))\n",
    "        \n",
    "        # Plot components\n",
    "        for i, comp in enumerate(components):\n",
    "            plt.plot([0.2, 0.8], [y_positions[i], y_positions[i]], 'b-', linewidth=2)\n",
    "            plt.text(0.1, y_positions[i], comp, ha='right', va='center')\n",
    "        \n",
    "        # Add arrows\n",
    "        for i in range(len(components)-1):\n",
    "            plt.arrow(0.5, y_positions[i], 0, y_positions[i+1]-y_positions[i],\n",
    "                     head_width=0.02, head_length=0.02, fc='k', ec='k')\n",
    "        \n",
    "        plt.title('LSTM-Hypergraph Model Architecture')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "def calculate_returns(stock_data):\n",
    "    returns = stock_data.pct_change().dropna()\n",
    "    return returns\n",
    "\n",
    "# Test function with visualization\n",
    "def test_model_with_hypergraph(model, stock_data, incidence_matrix):\n",
    "    time_steps = stock_data.shape[0] - 1\n",
    "    current_features = stock_data[:-1].values.reshape(1, time_steps, stock_data.shape[1])\n",
    "    next_day_returns = calculate_returns(stock_data).values.reshape(1, time_steps, stock_data.shape[1])\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model(current_features, incidence_matrix)\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    mse_loss = tf.keras.losses.MeanSquaredError()\n",
    "    test_mse = mse_loss(next_day_returns, predictions)\n",
    "    test_rmse = tf.sqrt(test_mse)\n",
    "    print(f\"Test RMSE: {test_rmse.numpy()}\")\n",
    "    \n",
    "    # Visualize predictions vs actual\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, ticker in enumerate(stock_data.columns):\n",
    "        plt.subplot(3, 2, i+1)\n",
    "        plt.plot(next_day_returns[0, :, i], label='Actual', alpha=0.7)\n",
    "        plt.plot(predictions[0, :, i], label='Predicted', alpha=0.7)\n",
    "        plt.title(f'{ticker} Returns')\n",
    "        plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    # Define tickers and date range\n",
    "    tickers = ['AAPL', 'MSFT', 'GOOG', 'AMZN', 'TSLA', 'NFLX']\n",
    "    start_date = '2020-01-01'\n",
    "    end_date = '2023-01-01'\n",
    "    \n",
    "    # Fetch stock data\n",
    "    stock_data = fetch_stock_data(tickers, start_date, end_date)\n",
    "    \n",
    "    # Create and visualize hypergraph structure\n",
    "    num_clusters = 3\n",
    "    H, _ = create_hyperedges_from_correlation(stock_data, num_clusters)\n",
    "    \n",
    "    # Create and visualize model\n",
    "    lstm_units = 64\n",
    "    num_tickers = len(tickers)\n",
    "    model = LSTMHypergraphModel(lstm_units=lstm_units, \n",
    "                               num_clusters=num_clusters, \n",
    "                               num_tickers=num_tickers)\n",
    "    model.visualize_architecture()\n",
    "    \n",
    "    # Test model and visualize results\n",
    "    test_model_with_hypergraph(model, stock_data, H)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
